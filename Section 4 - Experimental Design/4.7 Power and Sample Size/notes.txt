One of the most frustrating things about statistics is that we can go to all the trouble (and expense) of implementing a study, only to find that there are no significant differences between any of the treatments.  When this happens we have to wonder:  Are there really no differences between the treatments, or was the experiment "under-powered"?  In order to have reasonable chance of detecting significance differences (when there are significant differences), the sample sizes in the experiment must be large enough to overcome the ambient variability (a.k.a. background 'noise'). The question "How large should the sample be?" is very important, and needs to be addressed in the planning stages of an experiment.  

Think back to all of the calculations we have done this semester.  How many of them involved the sample size (n)?  If you answered “All of them” you'd be right.  The value of n occurs either explicitly or implicitly in every formula we have encountered -- it is used to calculate the mean (we divide by n) and the standard error of the mean (we divide by the square root of n) -- and these two quantities are the basis of all our inference.

To answer the question: “How large should the sample be?”, we need to consider the primary objective of the study.  Are we trying to achieve a certain precision in the treatment means?  (That is, do we want the standard errors of the means to be small?  If so, how small?)   If we are interested in detecting a difference between two treatments, then how big of a difference do we want to be able to detect?  These are only two of the many questions we must consider when deciding on an appropriate sample size.  